# 分页查询

Elasticsearch 提供了多种分页方式来处理大数据集的查询，主要的三种分页方式如下：

### 方式一：from size

- 这是最直观的分页方式，类似于 SQL 查询中的 LIMIT 和 OFFSET。
- 在请求中指定 from 和 size 参数来控制结果集的起始位置和大小。

```
GET user/_search
{
  "from": 0,
  "size": 10,
  "sort": [{"id": "asc"}],
  "query": { "match_all": {} }
}
```

```
"浅"分页可以理解为简单意义上的分页。它的原理很简单，就是查询前20条数据，然后截断前10条，只返回10-20的数据。这样其实白白浪费了前10条的查询。

其中，from定义了目标数据的偏移值，size定义当前返回的数目。默认from为0，size为10，即所有的查询默认仅仅返回前10条数据。

性能上：越往后的分页，执行的效率越低。总体上会随着from的增加，消耗时间也会增加。而且数据量越大，就越明显！

注意：因为es是基于分片的，假设有5个分片，from=100，size=10。则会根据排序规则从5个分片中各取回110条数据，然后汇总成550条数据，最后选择第100条后面的10条数据返回给客户端。
```

from+size查询在10000-50000条数据（1000到5000页）以内的时候还是可以的，但是如果数据过多的话，就会出现深分页问题。

```java

@Test
public void test_from_size() throws Exception {
    SearchRequest request = new SearchRequest().indices(ES_INDEX);
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder
//                    .query(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery("name", "张张")))
            .sort("id", SortOrder.ASC)
            .from(50)
            .size(3).trackTotalHits(true);

    request.source(sourceBuilder);
    SearchResponse response = getClient().search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    System.out.println("took:" + response.getTook());
    System.out.println("timeout:" + response.isTimedOut());
    System.out.println("total:" + hits.getTotalHits());
    System.out.println("MaxScore:" + hits.getMaxScore());
    System.out.println("Aggregations:" + JSONUtil.toJsonStr(response.getAggregations()));
    for (SearchHit hit : hits) {
        System.out.println(hit.getSourceAsString());
    }
}
```

### 方式二：scroll

```
scroll，就是为解决深分页问题，而出现，scroll查询每次只能获取一页的内容，然后会返回一个scroll_id。根据返回的这个scroll_id可以不断地获取下一页的内容，直到数据读取完毕或者scroll_id保留时间截止，所以scroll并不适用于有跳页的情景。

根据官方文档的说法，scroll的搜索上下文会在scroll的保留时间截止后自动清除，但是我们知道scroll是非常消耗资源的，所以一个建议就是当不需要了scroll数据的时候，尽可能快的把scroll_id显式删除掉。

scroll 的方式，官方的建议不用于实时的请求（一般用于数据导出），因为每一个 scroll_id 不仅会占用大量的资源，而且会生成历史快照，对于数据的变更不会反映到快照上。
```

- 缺点：Scroll 不适合实时查询，且需要管理 Scroll ID，以及在长时间未使用的情况下可能会被清理。

```
# 1、初始化 Scroll
# scroll：定义了 Scroll 上下文保持的时间长度，通常设置为几分钟到几小时不等，例如 5m 表示保持 5 分钟。
GET user/_search?scroll=5m
{
  "sort": [{ "id": "asc"  }],
  "query": { "match_all": { } },
  "size": 5 # 每次返回的文档数量
}
# 请求成功后，你会得到一个响应，其中包含了一个 hits 数组和一个 _scroll_id 字段。_scroll_id 将用于后续的 Scroll 请求。

# 2、获取下一页更多数据
# 使用 _scroll_id 来获取更多的数据。这可以通过发送一个 GET 请求到 _search/scroll 端点完成，并将 _scroll_id 作为请求体的一部分。
# tips: 每次请求都会返回一个新的 _scroll_id，这是因为旧的 _scroll_id 会在每次请求后失效，以防止内存泄漏。
GET _search/scroll?scroll=5m
{
  "scroll_id": "FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFmdSVGdkTmhNUjJXVUczV2lleWJBbFEAAAAAAAPN8RZPVFM5ekRiclE2U0k2LXpEN3AwZS1n"
}

# 3、清除 Scroll 上下文
# 当不再需要 Scroll 上下文时，可以使用 DELETE _search/scroll 端点来清除上下文，释放资源。
DELETE /_search/scroll
{
  "scroll_id": ["FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFmdSVGdkTmhNUjJXVUczV2lleWJBbFEAAAAAAAPN8RZPVFM5ekRiclE2U0k2LXpEN3AwZS1n"]
}

# 或清除所有的scroll
DELETE _search/scroll/_all
```

```java

@Test
public void test_scroll() throws Exception {
    // 保持5分钟
    Scroll scroll = new Scroll(TimeValue.timeValueMinutes(5L));
    SearchRequest request = new SearchRequest().indices(ES_INDEX).scroll(scroll);

    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder
//                    .query(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery("name", "张张")))
            .sort("id", SortOrder.ASC).size(3).trackTotalHits(true);

    request.source(sourceBuilder);
    SearchResponse response = getClient().search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    System.out.println("took:" + response.getTook());
    System.out.println("timeout:" + response.isTimedOut());
    System.out.println("total:" + hits.getTotalHits());
    System.out.println("MaxScore:" + hits.getMaxScore());
    System.out.println("Aggregations:" + JSONUtil.toJsonStr(response.getAggregations()));
    for (SearchHit hit : hits) {
        System.out.println(hit.getSourceAsString());
    }

    List<String> scrollIdList = Lists.newArrayList();

    // 下一页
    String scrollId = response.getScrollId();
    int sum = 1;
    while (CollUtil.isNotEmpty(hits)) {
        sum++;
        if (sum > 3) {
            break;
        }
        SearchScrollRequest scrollRequest = new SearchScrollRequest(scrollId);
        scrollRequest.scroll(scroll);
        response = getClient().scroll(scrollRequest, RequestOptions.DEFAULT);
        scrollId = response.getScrollId();
        hits = response.getHits();
        System.out.println("scrollId:" + scrollId);
        for (SearchHit hit : hits) {
            System.out.println("下一页：" + hit.getSourceAsString());
        }
        scrollIdList.add(scrollId);
    }

    // 清除 Scroll 上下文
    clearScrollId(scrollIdList);
}

private void clearScrollId(List<String> scrollIdList) throws IOException {
    ClearScrollRequest clearScrollRequest = new ClearScrollRequest();
    clearScrollRequest.setScrollIds(scrollIdList);
    getClient().clearScroll(clearScrollRequest, RequestOptions.DEFAULT);
}
```

### 方式三：search after

- Search After 是基于排序字段的值来进行分页，而不是基于文档的偏移量。
- 它使用上一页最后一个文档的排序值作为下一个请求的起始点。
- 这种方式在有新数据不断写入的情况下表现更好，因为它避免了 from 和 size 方式可能出现的重复结果。
- 缺点：不适合跳跃式分页，即从第一页直接跳转到第五页等。

```
GET user/_search
{
  "size": 20,
  "sort": [{ "id": "asc"  }],
  "query": { "match_all": { } },
  "search_after": [3]
}
```

```java

@Test
public void test_search_after_01() throws Exception {
    SearchRequest request = new SearchRequest().indices(ES_INDEX);

    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder
//                    .query(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery("name", "张张")))
            .sort("id", SortOrder.ASC).from(0).size(3).trackTotalHits(true);

    request.source(sourceBuilder);
    SearchResponse response = getClient().search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    for (SearchHit hit : hits) {
        System.out.println(hit.getSourceAsString());
    }

    if (hits.getHits().length == 0) {
        return;
    }
    // 拿到最后一条数据的排序值
    Object[] sortValues = hits.getAt(hits.getHits().length - 1).getSortValues();
    System.out.println("最后一条数据排序值：" + Arrays.toString(sortValues)); // new Object[]{3}

    // 下一页 设置上一页拿到的排序值
    request.source().searchAfter(sortValues);
    response = getClient().search(request, RequestOptions.DEFAULT);
    for (SearchHit hit : response.getHits()) {
        System.out.println("下一页：" + hit.getSourceAsString());
    }
}

@Test // 根据上一页排序值直接查询下一页数据
public void test_search_after_02() throws Exception {
    SearchRequest request = new SearchRequest().indices(ES_INDEX);

    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder
//                    .query(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery("name", "张张")))
            .sort("id", SortOrder.ASC).from(0) // 有searchAfter 时 from值只能为0
            .size(3).trackTotalHits(true).searchAfter(new Object[]{3}); // 第一页数据中拿到的最后一条数据的排序值 -- hits.getAt(hits.getHits().length - 1).getSortValues();

    request.source(sourceBuilder);
    SearchResponse response = getClient().search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    System.out.println("took:" + response.getTook());
    System.out.println("timeout:" + response.isTimedOut());
    System.out.println("total:" + hits.getTotalHits());
    System.out.println("MaxScore:" + hits.getMaxScore());
    System.out.println("Aggregations:" + JSONUtil.toJsonStr(response.getAggregations()));
    for (SearchHit hit : hits) {
        System.out.println(hit.getSourceAsString());
    }
}
```